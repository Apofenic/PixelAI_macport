#!/usr/bin/env python3
"""
Local AI Generator for Aseprite - Enhanced Startup Script
Professional startup script with improved error handling and user experience.
Version 2.0 - Ready for Publishing
"""
import sys
import os
import subprocess
import platform
import shutil
import time
from pathlib import Path

def print_banner():
    """Display startup banner with version info."""
    print("\n" + "="*60)
    print("üéÆ LOCAL AI GENERATOR FOR ASEPRITE v2.0")
    print("üé® Professional AI-Powered Pixel Art Generation")
    print("="*60)

def print_section(title):
    """Print a formatted section header."""
    print(f"\nüìã {title}")
    print("-" * (len(title) + 4))

def check_python_version():
    """Check if Python version meets requirements."""
    version = sys.version_info
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("‚ùå Python 3.8+ is required")
        print(f"   Current version: {version.major}.{version.minor}.{version.micro}")
        print("   Please upgrade Python from https://python.org")
        return False
    
    print(f"‚úÖ Python {version.major}.{version.minor}.{version.micro} - OK")
    return True

def install_dependencies():
    """Install required dependencies with progress indication."""
    print_section("Installing Dependencies")
    
    # Check if dependencies are already installed
    print("üîç Checking if dependencies are already installed...")
    try:
        import torch
        import diffusers
        import flask
        import peft
        import cv2
        print("‚úÖ All dependencies already installed!")
        return True
    except ImportError as e:
        print(f"üì¶ Some dependencies missing: {e}")
        print("üîÑ Installing required packages...")
    
    # Upgrade pip first
    print("üì¶ Upgrading pip...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])
        print("‚úÖ Pip upgraded")
    except subprocess.CalledProcessError:
        print("‚ö†Ô∏è  Warning: Could not upgrade pip, continuing...")
    
    # Install PyTorch first (largest package)
    print("\nüî• Installing PyTorch (this is the largest download)...")
    print("üì• This may take 5-10 minutes depending on your internet connection...")
    print("üí° The process may appear frozen - this is normal, please wait...")
    
    torch_installed = False
    
    # Try CUDA version first if available
    if platform.system() == "Windows":
        print("üéÆ Trying PyTorch with CUDA support...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", 
                "torch", "torchvision", "torchaudio",
                "--index-url", "https://download.pytorch.org/whl/cu121"
            ])
            print("‚úÖ PyTorch with CUDA installed successfully")
            torch_installed = True
        except subprocess.CalledProcessError:
            print("‚ö†Ô∏è  CUDA version failed, trying CPU version...")
    
    # Fallback to CPU version
    if not torch_installed:
        print("üíª Installing PyTorch CPU version...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install",
                "torch", "torchvision", "torchaudio",
                "--index-url", "https://download.pytorch.org/whl/cpu"
            ])
            print("‚úÖ PyTorch CPU version installed successfully")
            torch_installed = True
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to install PyTorch: {e}")
            return False
    
    # Install other packages
    print("\nüìö Installing AI and web server libraries...")
    print("üì• This may take another 5-10 minutes...")
    
    other_requirements = [
        "diffusers>=0.27.0", "transformers>=4.40.0", "accelerate>=0.29.0",
        "flask>=2.3.0", "flask-cors>=4.0.0", "pillow>=9.5.0",
        "numpy>=1.24.0", "safetensors>=0.4.0", "peft>=0.11.0",
        "opencv-python", "scipy", "timm", "einops", "kornia"
    ]
    
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install"
        ] + other_requirements)
        print("‚úÖ All other dependencies installed successfully")
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è  Some packages failed, trying individual installation...")
        
        # Try installing packages individually
        failed_packages = []
        for package in other_requirements:
            try:
                print(f"üì¶ Installing {package}...")
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", package
                ])
                print(f"‚úÖ {package} installed")
            except subprocess.CalledProcessError:
                print(f"‚ùå Failed to install {package}")
                failed_packages.append(package)
        
        if failed_packages:
            print(f"‚ö†Ô∏è  Some packages failed: {failed_packages}")
            print("üîÑ Trying alternative installation method...")
            try:
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", "--no-cache-dir"
                ] + failed_packages)
                print("‚úÖ Alternative installation successful")
            except subprocess.CalledProcessError:
                print("‚ùå Alternative installation also failed")
                print("\nüîß Troubleshooting suggestions:")
                print("   ‚Ä¢ Check your internet connection")
                print("   ‚Ä¢ Free up disk space (need 5-10GB)")
                print("   ‚Ä¢ Try running as Administrator")
                print("   ‚Ä¢ Temporarily disable antivirus software")
                return False
    
    # Verify installation
    print("\nüîç Verifying installation...")
    try:
        import torch
        print(f"‚úÖ PyTorch {torch.__version__} - Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
        
        import diffusers
        print(f"‚úÖ Diffusers {diffusers.__version__}")
        
        import flask
        print(f"‚úÖ Flask {flask.__version__}")
        
        print("üéâ All dependencies installed and verified!")
        return True
        
    except ImportError as e:
        print(f"‚ùå Verification failed: {e}")
        print("Some packages may not have installed correctly.")
        return False

def select_startup_model():
    """Interactive model selection with improved UI."""
    print_section("Base Model Selection")
    
    models = [
        {
            "name": "stabilityai/stable-diffusion-xl-base-1.0",
            "description": "SDXL Base (Recommended) - High quality, ~7GB",
            "size": "~7GB"
        },
        {
            "name": "runwayml/stable-diffusion-v1-5",
            "description": "SD 1.5 - Faster, smaller, ~4GB",
            "size": "~4GB"
        }
    ]
    
    print("Choose a base model to load on startup:")
    print()
    
    for i, model in enumerate(models):
        print(f"  [{i+1}] {model['description']}")
        print(f"      Size: {model['size']}")
        print()
    
    print(f"  [{len(models)+1}] None (load manually later)")
    print()
    
    while True:
        try:
            choice_str = input(f"Enter choice [1-{len(models)+1}] (default: 1): ").strip()
            choice = int(choice_str) if choice_str else 1
            
            if 1 <= choice <= len(models):
                selected = models[choice - 1]
                print(f"‚úÖ Selected: {selected['name']}")
                return selected["name"]
            elif choice == len(models) + 1:
                print("‚úÖ No model will be loaded on startup")
                return "none"
            else:
                print(f"‚ùå Invalid choice. Please enter 1-{len(models)+1}")
                
        except ValueError:
            print("‚ùå Please enter a valid number")

def configure_offline_mode():
    """Configure offline mode with explanation."""
    print_section("Network Configuration")
    
    print("Offline Mode Options:")
    print("  ‚Ä¢ Online:  Download models from internet (recommended for first run)")
    print("  ‚Ä¢ Offline: Use only cached models (faster startup, requires previous download)")
    print()
    
    response = input("Run in Offline Mode? [y/N]: ").lower().strip()
    
    if response in ['y', 'yes']:
        print("‚úÖ Offline mode enabled - using cached models only")
        return True
    else:
        print("‚úÖ Online mode enabled - models will download as needed")
        return False

def setup_directories():
    """Create necessary directories with proper structure."""
    print_section("Setting Up Directories")
    
    directories = ["loras", "models", "cache"]
    
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"üìÅ Created/verified: {directory}/")
    
    print("‚úÖ Directory structure ready")

def check_system_requirements():
    """Check system requirements and provide recommendations."""
    print_section("System Requirements Check")
    
    try:
        import psutil
        
        # Memory check
        memory_gb = psutil.virtual_memory().total / (1024**3)
        print(f"üíæ RAM: {memory_gb:.1f}GB")
        
        if memory_gb < 8:
            print("‚ö†Ô∏è  Warning: Less than 8GB RAM detected")
            print("   Consider closing other applications for better performance")
        else:
            print("‚úÖ RAM: Sufficient")
        
        # Disk space check
        disk_free = psutil.disk_usage('.').free / (1024**3)
        print(f"üíΩ Free disk space: {disk_free:.1f}GB")
        
        if disk_free < 10:
            print("‚ö†Ô∏è  Warning: Less than 10GB free space")
            print("   AI models require significant storage space")
        else:
            print("‚úÖ Disk space: Sufficient")
            
    except ImportError:
        print("‚ÑπÔ∏è  Install psutil for detailed system info: pip install psutil")
    
    # GPU check
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"üéÆ GPU: {gpu_name}")
            print(f"üî• VRAM: {vram_gb:.1f}GB")
            
            if vram_gb < 6:
                print("‚ö†Ô∏è  Warning: Less than 6GB VRAM")
                print("   Consider using smaller models or reducing batch size")
            else:
                print("‚úÖ GPU: Excellent for AI generation")
        else:
            print("‚ö†Ô∏è  No CUDA GPU detected - using CPU (slower)")
            print("   Consider using a NVIDIA GPU for better performance")
    except ImportError:
        print("üì¶ PyTorch not yet installed")

def main():
    """Main startup function with comprehensive setup."""
    print_banner()
    
    # Python version check
    if not check_python_version():
        input("\nPress Enter to exit...")
        sys.exit(1)
    
    # System requirements check
    check_system_requirements()
    
    # Check and install dependencies
    print("\nüîß Checking Python dependencies...")
    if not install_dependencies():
        print("\n‚ùå Dependency installation failed!")
        print("üîß You can try manual installation:")
        print("   pip install torch torchvision torchaudio diffusers transformers flask")
        input("\nPress Enter to exit...")
        sys.exit(1)
    
    # Setup directories
    setup_directories()
    
    # Model selection
    chosen_model = select_startup_model()
    
    # Offline mode configuration
    offline_mode = configure_offline_mode()
    
    # Final preparation
    print_section("Starting Server")
    
    # Clean up any Python cache
    try:
        if os.path.exists("__pycache__"):
            shutil.rmtree("__pycache__")
        print("üßπ Cleaned Python cache")
    except:
        pass
    
    # Start the server
    try:
        print("üöÄ Importing server modules...")
        from sd_server import main as run_server
        
        print("üåü Server starting with configuration:")
        print(f"   ‚Ä¢ Model: {chosen_model}")
        print(f"   ‚Ä¢ Offline: {offline_mode}")
        print(f"   ‚Ä¢ URL: http://127.0.0.1:5000")
        
        print("\n" + "="*60)
        print("üéâ LOCAL AI GENERATOR SERVER STARTING...")
        print("üé® Ready for Aseprite plugin connection!")
        print("="*60)
        
        # Start the server
        run_server(default_model_to_load=chosen_model, offline=offline_mode)
        
    except KeyboardInterrupt:
        print("\n\nüëã Server stopped by user")
        print("Thank you for using Local AI Generator!")
        
    except Exception as e:
        import traceback
        print(f"\n‚ùå Server error occurred:")
        print(f"   {str(e)}")
        print("\nüêõ Full error details:")
        traceback.print_exc()
        print("\nüîß Troubleshooting:")
        print("   ‚Ä¢ Check if port 5000 is available")
        print("   ‚Ä¢ Verify all dependencies are installed")
        print("   ‚Ä¢ Try running as administrator")
        input("\nPress Enter to exit...")
        sys.exit(1)

if __name__ == "__main__":
    main()